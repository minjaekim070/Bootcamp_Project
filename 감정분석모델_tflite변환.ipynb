{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minjaekim070/Bootcamp_Project/blob/main/%EA%B0%90%EC%A0%95%EB%B6%84%EC%84%9D%EB%AA%A8%EB%8D%B8_tflite%EB%B3%80%ED%99%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "import os\n",
        "class FacialExpressionModel(object):\n",
        "    EMOTIONS_LIST = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
        "\n",
        "    def __init__(self, model_json_file, model_weights_file):\n",
        "        with open(model_json_file, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            self.loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "        self.loaded_model.load_weights(model_weights_file)\n",
        "        print(\"Model loaded from disk\")\n",
        "        self.loaded_model.summary()\n",
        "\n",
        "    def predict_emotion(self, img):\n",
        "      self.preds = self.loaded_model.predict(img)\n",
        "\n",
        "      # EMOTIONS_LIST에 있는 레이블과 예측 결과를 딕셔너리로 생성\n",
        "      emotion_dict = {emotion: round(score, 3) for emotion, score in zip(self.EMOTIONS_LIST, self.preds[0])}\n",
        "\n",
        "      # 각각의 감정에 해당하는 확률 값을 따로 모으는 딕셔너리\n",
        "      emotions_by_type = {\n",
        "          'happy': [],\n",
        "          'sad': [],\n",
        "          'surprise': [],\n",
        "          'neutral': [],\n",
        "      }\n",
        "\n",
        "      emotion_by_type = {\n",
        "      'happy': emotion_dict['happy'],\n",
        "      'sad': emotion_dict['sad'] + emotion_dict['disgust'],\n",
        "      'neutral': emotion_dict['neutral']  + emotion_dict['angry'] + emotion_dict['fear'],\n",
        "      'surprise': emotion_dict['surprise']\n",
        "       }\n",
        "\n",
        "      return emotion_by_type\n",
        "\n",
        "# Provide the paths to the model JSON file and model weights file\n",
        "model_json = '/content/drive/MyDrive/감정분석 모델/model.json'\n",
        "model_weights = '/content/drive/MyDrive/감정분석 모델/weights.h5'\n",
        "\n",
        "# Load the model\n",
        "model = FacialExpressionModel(model_json, model_weights)"
      ],
      "metadata": {
        "id": "ns1_F436UhpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 작동"
      ],
      "metadata": {
        "id": "DxnwXeQjzTKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 입력 shape과 출력 shape 확인\n",
        "input_shape = model.loaded_model.input_shape\n",
        "output_shape = model.loaded_model.output_shape\n",
        "print(\"Input shape:\", input_shape)\n",
        "print(\"Output shape:\", output_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "490RlSGadTcv",
        "outputId": "30a4c5e7-55bf-4581-a582-504874a587b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (None, 48, 48, 1)\n",
            "Output shape: (None, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fer"
      ],
      "metadata": {
        "id": "C8ZX5rKghJHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fer import FER\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "c6eZNHgwhG_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/운전자 이상탐지/Training/original/bus/R_001_60_M'\n",
        "extensions = ['jpg']\n",
        "\n",
        "photo_list = []\n",
        "for ext in extensions:\n",
        "    photo_list.extend(glob.glob(os.path.join(folder_path, f'*.{ext}')))"
      ],
      "metadata": {
        "id": "Yi0OqFSsdZAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "image = '/content/drive/MyDrive/운전자 이상탐지/Training/original/bus/R_001_60_M/R_001_60_M_01_M0_G0_C0_05.jpg'\n",
        "image = cv2.imread(image)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "3HDFQ_0jmWAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = FER()\n",
        "detector.detect_emotions(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rtPoQKLwp-0",
        "outputId": "85b452b4-af92-4b82-9fec-049269d21b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'box': array([181, 601, 357, 357], dtype=int32),\n",
              "  'emotions': {'angry': 0.07,\n",
              "   'disgust': 0.01,\n",
              "   'fear': 0.09,\n",
              "   'happy': 0.04,\n",
              "   'sad': 0.51,\n",
              "   'surprise': 0.05,\n",
              "   'neutral': 0.24}}]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 축소\n",
        "resized_image = cv2.resize(image, (48,48))\n",
        "\n",
        "#bounding_box\n",
        "x,y,w,h = 219, 628, 302, 302  #bounding box 값 가변\n",
        "resized_image = image[y:y+h,x:x+w]\n",
        "resized_image = cv2.resize(resized_image, (48,48))\n",
        "cv2_imshow(resized_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "id": "nYV-8XSOwnCa",
        "outputId": "549f884c-06a7-4cea-9406-d92a23b0be4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=48x48>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 흑백 이미지로 변환\n",
        "gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "input_data = gray_image[np.newaxis, :, :, np.newaxis]\n",
        "print(input_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B7ekvVHpnOu",
        "outputId": "e2d8ab5c-0227-4f1c-cae4-7a336395b791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 48, 48, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict_emotion(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lruWpBjKlmK_",
        "outputId": "fcf0dbaa-6914-49c6-962d-9ca2f0b28525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 177ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'happy': 0.006, 'sad': 0.142, 'neutral': 0.731, 'surprise': 0.121}"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tflite 파일 변환"
      ],
      "metadata": {
        "id": "KWkM7I3z1EaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "\n",
        "# Convert Keras model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model.loaded_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TensorFlow Lite model to a file\n",
        "tflite_model_path = '/content/drive/MyDrive/감정분석 모델/model.tflite'\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TensorFlow Lite model saved to\", tflite_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrycKQ3k1F3p",
        "outputId": "15f5b9e6-14f3-4546-9202-71bc3559317e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Lite model saved to /content/drive/MyDrive/감정분석 모델/model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKr3pAGF1SC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}